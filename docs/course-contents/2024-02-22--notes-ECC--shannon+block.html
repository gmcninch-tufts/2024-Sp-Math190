<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Math190-Tufts University - Shannon's Theorem; block codes</title>
	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>	
        <link rel="stylesheet" href="../css/default.css" />
	<link rel="stylesheet" href="../css/haddock.css" />
	
	<link href="https://fonts.googleapis.com/css?family=Lato:400,700" type="text/css" rel="stylesheet" media="screen" />
	<link href="https://fonts.googleapis.com/css?family=Arimo:400,700" type="text/css" rel="stylesheet" media="screen" />
	<link href="https://fonts.googleapis.com/css?family=Roboto:400,700" type="text/css" rel="stylesheet" media="screen" />
	<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" type="text/css" rel="stylesheet" media="screen" />
	<link href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" type="text/css" rel="stylesheet" media="screen" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous" />			
    </head>
    <body>
        <header>
          <div class="logo">
            <a href="../">
	      Math190 - Spring 2024 - Tufts Univ</a>
          </div>
          <nav>
            <a href="../about.html">About</a>
	    <a href="../course-pages/Math190--course-info.html">Info</a>	    
            <a href="../archive.html">Archive</a>
          </nav>
        </header>

        <main role="main">
            <h1>Shannon's Theorem; block codes</h1>
            <article>
    <section class="header">
        Posted on 2024-02-22
        
    </section>
    <section>
        <h1 id="overview">Overview</h1>
<p>So far, we have chosen to use the term <em>code</em> for a vector subspace
<span class="math inline">\(C\)</span> of <span class="math inline">\(\mathbb{F}_q^n\)</span>. The idea is that we are interested in encoding some
data by identifying it with vectors in <span class="math inline">\(\mathbb{F}_q^k\)</span>.</p>
<p>If <span class="math inline">\(G\)</span> is a <em>generator matrix</em> for our code in <em>standard form</em>, then we <em>encode</em>
our data: given a vector <span class="math inline">\(v \in \mathbb{F}_q^k\)</span>, the encoded version is
<span class="math display">\[v \cdot G \in \mathbb{F}_q^n.\]</span></p>
<p>Note that – since <span class="math inline">\(G\)</span> is in standard form – if <span class="math inline">\(v = (v_1,\cdots,v_k)\)</span> then
<span class="math display">\[v\cdot G = (v_1,\cdots,v_k,w_{k+1},\cdots,w_n)\]</span>
for some scalars <span class="math inline">\(w_j \in \mathbb{F}_q.\)</span></p>
<p>Our intent is to “<em>transmit</em>” this encoded data <span class="math inline">\(v \cdot G\)</span>, possibly
through some noisy channels that may result in transmission errors. At
the other end, some vector <span class="math inline">\(w\)</span> in <span class="math inline">\(\mathbb{F}_q^n\)</span> is received, and the hope
is to recover the vector <span class="math inline">\(v\)</span> from the received vector <span class="math inline">\(w\)</span>.</p>
<p>The field of <em>Information Theory</em> formulates a way to reason about
such systems; we are going to sketch a rudimentary description.</p>
<h1 id="noisy-channels-and-shannons-theorem">Noisy Channels and Shannon’s Theorem</h1>
<p>We consider finite sets <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span> (say <span class="math inline">\(S = \{s_1,\cdots,s_n\}\)</span> and
<span class="math inline">\(T = \{t_1,\cdots,t_m\}\)</span>).</p>
<p>We consider <em>random variables</em> <span class="math inline">\(X\)</span> on <span class="math inline">\(S\)</span> and <span class="math inline">\(Y\)</span> on <span class="math inline">\(T\)</span>. In particular,
we may consider probabilities:</p>
<p><span class="math display">\[P(X=s) = p_s, \quad \text{the probability that the random var $X$
takes value $s \in S$}\]</span></p>
<p><span class="math display">\[P(Y=t) = q_t, \quad \text{the probability that the random var $Y$
takes value $t \in T$}\]</span></p>
<p>We view the elements of the set <span class="math inline">\(S\)</span> as the data we <em>send</em> through some
transmission channel, and <span class="math inline">\(T\)</span> as the data we <em>receive</em>.</p>
<p>In the case of our linear codes <span class="math inline">\(C \subset \mathbb{F}_q^n\)</span> described above,
<span class="math inline">\(S\)</span> would be <span class="math inline">\(\mathbb{F}_q^k\)</span> and <span class="math inline">\(T\)</span> would be <span class="math inline">\(\mathbb{F}_q^n\)</span>.</p>
<h2 id="block-codes">Block codes</h2>
<p>More generally, we consider <em>block codes</em> <span class="math inline">\(C \subset A^n\)</span>. Here <span class="math inline">\(A\)</span>
is an <em>alphabet</em>, and the code words in <span class="math inline">\(C\)</span> are just <span class="math inline">\(n\)</span>-tuples of
elements from <span class="math inline">\(A\)</span>. We write <span class="math inline">\(q = |A|\)</span>. We say that the <em>length</em> of the
code <span class="math inline">\(C\)</span> is <span class="math inline">\(n\)</span>.</p>
<p>In this setting, for our transmission channel we take <span class="math inline">\(S = C\)</span> and <span class="math inline">\(T = A^n\)</span>.</p>
<h2 id="channel">Channel</h2>
<p>A channel <span class="math inline">\(\Gamma\)</span> for transmission amounts to the following matrix
with rows indexed by the set <span class="math inline">\(S\)</span> and columns indexed by the set <span class="math inline">\(T\)</span>:
<span class="math display">\[p_{st} = P( Y = t \mid  X = s)\]</span>
i.e. the conditional probability that <span class="math inline">\(Y= t\)</span> given that <span class="math inline">\(X = s\)</span>.</p>
<dl>
<dt><strong>Example</strong></dt>
<dd>
<p>An example is the <em>binary symmetric channel</em>, where <span class="math inline">\(S = T = \{0,1\}\)</span> and the channel matrix <span class="math inline">\(\Gamma\)</span> is given by <span class="math display">\[(p_{st}) =
\begin{bmatrix} \phi &amp; 1 - \phi \\ 1 - \phi &amp; \phi \end{bmatrix}
\quad \text{for some $\phi \in [0,1]$}.\]</span></p>
<p>Here <span class="math inline">\(\phi\)</span> represents the probability that <span class="math inline">\(0\)</span> was received given that <span class="math inline">\(0\)</span> was sent,
and also the probability that <span class="math inline">\(1\)</span> was received given that <span class="math inline">\(1\)</span> was sent.</p>
</dd>
</dl>
<p>Note for example that if we know the channel matrix and if we know the
probabilities for the random variable <span class="math inline">\(X\)</span>, we find the probabilities for <span class="math inline">\(Y\)</span> via
<span class="math display">\[P(Y=t) = \sum_{s \in S} P(Y=t \mid X = s) \cdot P(X=s).\]</span></p>
<dl>
<dt><strong>Example</strong></dt>
<dd>
For the binary symmetric channel if we know that <span class="math inline">\(P(X=0) = p\)</span>, then
<span class="math display">\[P(Y=0) = \phi \cdot p + (1-\phi) (1-p).\]</span>
</dd>
</dl>
<h2 id="decoding">Decoding</h2>
<p>With notation as above, a <em>decoding</em> is a function <span class="math inline">\(\Delta:T \to S\)</span>. Think of it this way: given that <span class="math inline">\(t \in T\)</span> was received, the
decoding function “guesses” that <span class="math inline">\(\Delta(t) \in S\)</span> was sent.</p>
<p>The question is: how to identify a good decoding function.</p>
<p>Well, we can consider the probabilities that reflect how often a
decoding <span class="math inline">\(\Delta\)</span> is correct:</p>
<p><span class="math display">\[q_{\Delta(t),t} = P(X = \Delta(t) \mid Y = t)\]</span>
represents the probability that <span class="math inline">\(\Delta(t)\)</span> was sent given that <span class="math inline">\(t\)</span> was received.</p>
<p>The <em>average probability of a correct decoding</em> is given by
<span class="math display">\[P_{\operatorname{COR}} = \sum_{t \in T} q_t \cdot q_{\Delta(t),t}\]</span>
(remember that <span class="math inline">\(q_t = P(Y = t)\)</span>)</p>
<h2 id="maximum-likelihood-decoding">Maximum likelihood decoding</h2>
<p>A decoding <span class="math inline">\(\Delta:T \to S\)</span> is said to be a <em>maximal likelihood
decoding</em> if <span class="math display">\[p_{\Delta(t),t} \ge p_{s,t}\]</span> for every <span class="math inline">\(s \in S\)</span> and
every <span class="math inline">\(t \in T\)</span>.</p>
<p>Under some circumstances, one achieves maximal likelihood decoding
through <em>minimum distance decoding</em>.</p>
<p>For example, we have:</p>
<dl>
<dt><strong>Lemma</strong></dt>
<dd>
<p>For the binary symmetric channel and <span class="math inline">\(C \subset \mathbb{F}_2^n\)</span>, consider
the assignment <span class="math display">\[\Delta(v) = u\]</span> where <span class="math inline">\(u\)</span> is the closest neighbor
to <span class="math inline">\(v\)</span> in <span class="math inline">\(C\)</span> with respect to the Hamming distance.</p>
<p>Then <span class="math inline">\(\Delta\)</span> is <em>maximal likelihood decoding</em>.</p>
</dd>
</dl>
<h2 id="transmission-rate-and-capacity">Transmission rate and capacity</h2>
<p>For a block code <span class="math inline">\(C \subset A^n\)</span> with <span class="math inline">\(|A| = q\)</span>, the <em>transmission rate</em> of <span class="math inline">\(C\)</span>
is defined to be
<span class="math display">\[R = \dfrac{\log_q(|C|)}{n}\]</span></p>
<p>If <span class="math inline">\(A = \mathbb{F}_q\)</span> and <span class="math inline">\(C\)</span> is a linear code with <span class="math inline">\(k = \dim_{\mathbb{F}_q} C\)</span>, then
<span class="math display">\[R = k/n.\]</span></p>
<p>There is a notion of the <em>capacity</em> of a channel <span class="math inline">\(\Gamma\)</span>; it is a
number which in some sense encodes the theoretical maximum rate at
which information can be reliably transmitted over the channel; we
omit the definition here.</p>
<h2 id="shannons-theorem">Shannon’s Theorem</h2>
<dl>
<dt><strong>Theorem (Shannon)</strong></dt>
<dd>
<p>Let <span class="math inline">\(\delta &gt; 0\)</span> be given and let <span class="math inline">\(0 &lt; R\)</span> with <span class="math inline">\(R\)</span> less than the
channel capacity.</p>
<p>For every sufficiently large natural number <span class="math inline">\(n\)</span>, there is a code
of length <span class="math inline">\(n\)</span> and transmission rate <span class="math inline">\(\ge R\)</span> such that, using
maximum likelihood decoding, the probability
<span class="math inline">\(P_{\operatorname{COR}}\)</span> of a correct decoding satisfies
<span class="math display">\[P_{\operatorname{COR}} &gt; 1 - \delta.\]</span></p>
</dd>
</dl>
<p>This shows that, given a channel with non-zero capacity, there are
codes which allow us to communicate using the channel and decode with
a probability of a correct decoding arbitrary close to 1.</p>
<p>It is not constructive, of course – in some sense, this motivates the
subject: how to find the codes that work well?</p>
<hr />
<h1 id="bounds-for-block-codes">Bounds for block codes</h1>
<p>Here we consider an <em>alphabet</em> <span class="math inline">\(A\)</span> – thus <span class="math inline">\(A\)</span> is just a finite set,
of order <span class="math inline">\(|A| = q\)</span> – and a set of codewords <span class="math inline">\(C \subset A^n\)</span>; we call
<span class="math inline">\(n\)</span> the <em>length</em> of the codewords.</p>
<p>We consider the Hamming distance on <span class="math inline">\(A^n\)</span>: for <span class="math inline">\(u,v \in A^n\)</span>,
<span class="math display">\[\operatorname{dist}(u,v) = \#\{i \mid u_i \ne v_i\}\]</span> where e.g. <span class="math inline">\(u = (u_1,\cdots,u_n) \in A^n\)</span>. In words, the distance between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>
is the number of coordinates in which the tuples differ.</p>
<p>It is straightforward to check that <span class="math inline">\(\operatorname{dist}\)</span> is a <em>metric</em> on the finite set
<span class="math inline">\(A^n\)</span>; in particular, the <em>triangle inequality</em> holds: for every <span class="math inline">\(u,v,w \in A^n\)</span> we have
<span class="math display">\[\operatorname{dist}(u,v) \le \operatorname{dist}(u,w) + \operatorname{dist}(w,v).\]</span></p>
<p>The <em>minimal distance</em> of <span class="math inline">\(C\)</span> is given by
<span class="math display">\[d = \min \{ \operatorname{dist}(u,v) \mid u,v \in C, u \ne v\}.\]</span></p>
<dl>
<dt><strong>Lemma</strong></dt>
<dd>
Using nearest neighbor decoding, a block code of minimal distance <span class="math inline">\(d\)</span>
can correct up to <span class="math inline">\((d-1)/2\)</span> errors.
</dd>
<dt><strong>Proof</strong></dt>
<dd>
<p>For every <span class="math inline">\(w \in A^n\)</span> and every <span class="math inline">\(u,v \in C\)</span> we have
<span class="math display">\[(*) \quad d \le \operatorname{dist}(u,v) \le \operatorname{dist}(u,w) + \operatorname{dist}(w,v).\]</span></p>
<p>Now, if <span class="math inline">\(\operatorname{dist}(u,w) \le (d-1)/2\)</span> and <span class="math inline">\(\operatorname{dist}(w,v) \le (d-1)/2\)</span> then
<span class="math inline">\(\operatorname{dist}(u,v) \le d-1\)</span>, contrary to <span class="math inline">\((*)\)</span>. Thus for any <span class="math inline">\(w\)</span> there is
at most one codeword <span class="math inline">\(u \in C\)</span> for which <span class="math inline">\(\operatorname{dist}(u,w) \le (d-1)/2\)</span>.</p>
<p>From the point of view of code transmission, if <span class="math inline">\(w \in A^n\)</span> is
<em>received</em> and no more than <span class="math inline">\((d-1)/2\)</span> of the components of <span class="math inline">\(w = (w_1,w_2,\cdots,w_n)\)</span> are erroneous, then nearest neighbor
decoding will find the codeword in <span class="math inline">\(C\)</span> that was transmitted.</p>
</dd>
<dt><strong>Example</strong> (<em>Repetition code</em>)</dt>
<dd>
<p>Consider a finite alphabet <span class="math inline">\(A\)</span> and the the codewords <span class="math inline">\(C=\{(a,a,\cdots,a) \in A^r \mid a \in A\}\)</span>.
Thus the data <span class="math inline">\(a \in A\)</span> is encoded by the redundant codeword <span class="math inline">\((a,a,\cdots,a)\)</span>.</p>
<p>The minimal distance between distinct codewords in <span class="math inline">\(C\)</span> is <span class="math inline">\(r\)</span>, so
the Lemma shows that using nearest neighbor decoding, this code
can correct up to <span class="math inline">\((r-1)/2\)</span> errors.</p>
<p>(Note that in this case nearest neighbor decoding amounts to
decoding <span class="math display">\[(a_1,a_2,\cdots,a_r)\]</span> by “majority vote”; in other
words, view <span class="math inline">\(\{a_1,a_2,\cdots,a_r\}\)</span> as a <em>multi-set</em> and choose an
element with maximal multiplicity.)</p>
</dd>
</dl>
<h2 id="counting-codes-with-given-parameters">Counting codes with given parameters</h2>
<p>Write <span class="math inline">\(A_q(n,d)\)</span> for the maximum size <span class="math inline">\(|C|\)</span> of a block code <span class="math inline">\(C \subset A^n\)</span> having
minimal distance <span class="math inline">\(d\)</span>.</p>
<p>We are going to prove some results about the quantity <span class="math inline">\(A_q(n,d)\)</span>.</p>
<p>We first compute the size of a “ball” in the metric space <span class="math inline">\((A^n,\operatorname{dist})\)</span>.</p>
<dl>
<dt><strong>Lemma</strong></dt>
<dd>
<p>For <span class="math inline">\(u \in A^n\)</span> and a natural number <span class="math inline">\(m\)</span> write:
<span class="math display">\[B_m(u)  = \{v \in A^n \mid \operatorname{dist}(u,v) \le m\}.\]</span></p>
<p>Let <span class="math display">\[\delta(m) = 1 + \dbinom{n}{1}(q-1) + \dbinom{n}{2}(q-1)^2 + \cdots + \dbinom{n}{m}(q-1)^m
= \sum_{j=0}^m \dbinom{n}{j}(q-1)^j.\]</span>
Then <span class="math inline">\(|B_m(u)| = \delta(m)\)</span>.</p>
</dd>
<dt><strong>Remark</strong></dt>
<dd>
<p>Note that if <span class="math inline">\(k \in \mathbb{N}\)</span>, <span class="math inline">\(k &gt; n\)</span> then we insist that <span class="math inline">\(\dbinom{n}{k} = 0\)</span>; in this case
“there are 0 ways of choosing precisely <span class="math inline">\(k\)</span> elements from a set of size <span class="math inline">\(n\)</span>.”</p>
<p>This is consistent e.g. with the formula
<span class="math display">\[\dbinom{n}{k} = \dfrac{n(n-1)\cdots(n-k+1)}{k!}\]</span>
since the factor <span class="math inline">\((n-n) = 0\)</span> appears in the numerator.</p>
</dd>
<dt><strong>Proof of Lemma</strong></dt>
<dd>
For each <span class="math inline">\(j = 0,1,\cdots,m\)</span> there are <span class="math inline">\(\dbinom{n}{j} \cdot (q-1)^j\)</span> elements of <span class="math inline">\(A^n\)</span> at distance precisely <span class="math inline">\(j\)</span> from <span class="math inline">\(u\)</span>.
</dd>
</dl>
<p>We may now state and prove the following:</p>
<dl>
<dt><strong>Theorem</strong> (<em>Gilbert-Varshamov Bound</em>)</dt>
<dd>
<span class="math display">\[A_q(n,d) \cdot \delta(d-1) \ge q^n.\]</span>
</dd>
<dt><strong>Proof</strong></dt>
<dd>
<p>Suppose that <span class="math inline">\(C \subset A^n\)</span> is a code with minimal distance <span class="math inline">\(d\)</span>
for which <span class="math inline">\(|C| = A_q(n,d)\)</span>.</p>
<p>Notice that
<span class="math inline">\(|C| \cdot \delta(d-1)\)</span> is the size of the disjoint union
<span class="math display">\[\bigsqcup_{u \in C} B_{d-1}(u).\]</span>.</p>
<p>Thus, if <span class="math display">\[|C|\cdot \delta(d-1) &lt; q^n = |A^n|\]</span> then
<span class="math display">\[\bigcup_{u \in C} B_{d-1}(u) \subsetneq A^n;\]</span>
thus, there is some
element <span class="math inline">\(v \in A^n\)</span> for which <span class="math display">\[v \not \in \bigcup_{u \in C}
B_{d-1}(u).\]</span> We then have <span class="math inline">\(\operatorname{dist}(u,v) \ge d\)</span> for every <span class="math inline">\(u \in C\)</span>.</p>
<p>This shows that <span class="math inline">\(C \cup \{v\} \subset A^n\)</span> is a code having
minimal distance <span class="math inline">\(d\)</span>, contradicting the assumption that <span class="math inline">\(|C| = A_q(n,d)\)</span>; i.e. contradicting the assumption that <span class="math inline">\(C\)</span> has maximal
size among codes <span class="math inline">\(C' \subset A^n\)</span> with minimal distance <span class="math inline">\(d\)</span>.</p>
</dd>
</dl>
    </section>
</article>

        </main>

        <footer>
	  <nav>
	    <a href="http://www.tufts.edu">
	      <i class="fas fa-chalkboard"></i>
	      Tufts
	    </a>	    
	    <a href="http://math.tufts.edu">
	      <i class="fas fa-chalkboard-teacher"></i>
	      Tufts Math
	    </a>
	    <a href="https://gmcninch-tufts.github.io/math">
	      <i class="fas fa-coffee"></i>
	      G McNinch
	    </a>
	    <a href="https://github.com/gmcninch-tufts">
	      <i class="fab fa-github"></i>
	      GitHub
	    </a>	    
	  </nav>
        </footer>
    </body>
</html>
